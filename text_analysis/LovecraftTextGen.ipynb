{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scikitlearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-b511208cf6a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mscikitlearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNLTK\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scikitlearn'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "from scikitlearn import NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows\n",
      " Volume Serial Number is 561F-2A4E\n",
      "\n",
      " Directory of C:\\projects\\python_learning\\text_analysis\\data\n",
      "\n",
      "06/07/2018  11:48 AM    <DIR>          .\n",
      "06/07/2018  11:48 AM    <DIR>          ..\n",
      "05/17/2018  05:45 PM            71,810 lovecraft.txt\n",
      "06/07/2018  11:48 AM             4,824 lovecraft_words.txt\n",
      "05/18/2018  07:28 AM               523 products.txt\n",
      "05/18/2018  08:20 AM           595,115 shakespear.txt\n",
      "               4 File(s)        672,272 bytes\n",
      "               2 Dir(s)  89,072,078,848 bytes free\n"
     ]
    }
   ],
   "source": [
    "! dir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/lovecraft_words.txt', 'r') as f:\n",
    "    lc_words = f.readlines()\n",
    "lc_words = [str(x).replace('*', '') for x in lc_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Aberrant, Abominable, Absurd, Abysmal, Acidic, Acrocephalic, Adhesive, Adipose, Airy, Alien, Ambiguous, Amoebic, Amorphous, Anarchic, Ancient, Angular, Animalistic, Animated, Anomalous, Antediluvian, Anthropophagous, Appalling, Appendaged, Aquatic, Ashen, Askew, Astounding, Atrocious, Awry, Baboon-Like, Baleful, Baneful, Bankrupt, Barbarous, Batrachian, Beastly, Bellowing, Bestial, Bilious, Bizarre, Blasphemous, Bleating, Bloated, Bloodshot, Blubbery, Boiling, Bombilating, Brutish, Bug-Eyed, Bulbous, Cacaphonous, Cackling, Cadaverous, Cancerous, Cellular, Changeable, Chaotic, Chattering, Chelonian, Chitinous, Chthonic, Clawed, Coarse, Colorless, Colossal, Confusing, Congealed, Conical, Convoluted, Corpse-Like, Corpulent, Corrupt, Creamy, Criminal, Croaking, Crustaceous, Crystalline, Cunning, Cyclopean, Cylindrical, Dank, Dark, Dazzling, Deafening, Deathless, Debased, Debauched, Decomposing, Deformed, Degenerate, Degraded, Delirious, Demonic, Depraved, Deranged, Detestable, Deviant, Devilish, Diabolical, Diffuse, Dire, Discordant, Diseased, Disfigured, Disgusting, Dislocated, Disordered, Dissolved, Distorted, Dreadful, Dripping, Effervescent, Effulgent, Effusive, Elastic, Elephantine, Elongated, Emaciated, Endless, Enlarged, Enormous, Enveloping, Evasive, Exaggerated, Excruciating, Extended, Fabulous, Faceless, Fantastic, Fearful, Fecund, Festering, Fetid, Fibrous, Fiendish, Fiery, Filthy, Fish-Like, Flabby, Flailing, Flatulent, Flowing, Fluctuating, Fluid, Foaming, Foul, Fractured, Fragrant, Frantic, Fungous, Furfuraceous, Furious, Gangrenous, Gargantuan, Gaunt, Ghastly, Ghoulish, Gibbering, Gigantic, Globular, Glutinous, Gluttonous, Gnashing, Gory, Grasping, Grayish, Greenish, Grim, Grisly, Gross, Grotesque, Gushing, Hairy, Hallucinatory, Hapless, Hateful, Hazy, Heaving, Hellish, Herpetiform, Hideous, Hircine, Hissing, Horned, Horrible, Horrific, Horrifying, Howling, Huge, Hump-Backed, Hybrid, Ichorous, Idiotic, Illogical, Immaterial, Immense, Immoral, Incestous, Incoherent, Incomplete, Incongruous, Incredible, Indistinct, Infected, Infernal, Infested, Inhuman, Insane, Insatiable, Insidious, Insipid, Invidious, Iridescent, Irrational, Irregular, Jabbering, Jaded, Jangling, Jaundiced, Jellified, Jumbled, Jutting, Kleptomaniacal, Leprous, Limp, Liquefied, Loathsome, Lumbering, Luminescent, Lumpy, Lunatic, Lurking, Mad, Maggoty, Malevolent, Malformed, Malicious, Malignant, Mangy, Massive, Melancholic, Membranous, Menacing, Mesmerizing, Metallic, Mildewed, Mindless, Miscarried, Misshapen, Moaning, Molten, Molting, Monstrous, Monumental, Morbid, Mordant, Morose, Mortifying, Mottled, Mouldering, Mucky, Mucous, Murderous, Murmuring, Mutilated, Nagging, Nameless, Nauseous, Nearsighted, Nebulous, Necromantic, Necrotic, Nictating, Nightmarish, Noiseless, Non-Euclidian, Nonsensical, Noxious, Numbing, Obese, Obscene, Obsequious, Octopoid, Odious, Odorous, Oily, Oleaginous, Ominous, Oozing, Organic, Otiose, Outlandish, Oval, Overgrown, Overripe, Pagan, Pale, Pallid, Palpitating, Palsied, Parasitic, Pasty, Peculiar, Pendulous, Perfidious, Perverse, Pestilent, Phlegmatic, Pitiless, Plastic, Pliable, Poisonous, Porous, Pregnant, Prodigious, Profane, Profuse, Prognathous, Pronged, Protoplasmic, Protuberant, Prurient, Pseudopoidal, Puckered, Pudding-Like, Pulsating, Pulsing, Pustular, Pustulent, Putrid, Pyriform, Quavering, Queasy, Quiescent, Quivering, Radiant, Rainbowed, Recrudescent, Rectangular, Reeking, Refulgent, Remorseless, Repellent, Reprehensible, Reptilian, Repugnant, Repulsive, Resplendent, Restless, Rheumy, Rigid, Roiling, Rotten, Rotting, Rough, Rubbery, Rugose, Sacrilegious, Sallow, Sanguine, Satanic, Scabby, Scabrous, Scaly, Scintillating, Screaming, Scrofulous, Scummy, Sebaceous, Seething, Segmented, Senescent, Senseless, Sepulchral, Shadowy, Shiny, Shivering, Shrieking, Shuffling, Sickly, Sightless, Simian, Sinewy, Singular, Skeletal, Sleepless, Slimy, Slippery, Slithering, Slobbering, Sluggish, Solemn, Sordid, Soundless, Spectral, Spherical, Spiky, Sponge-Like, Squamous, Stagnant, Stentorian, Sticky, Stupefying, Stupendous, Stygian, Sulphurous, Syrupy, Teeming, Tentacled, Terrible, Thickening, Thrashing, Throbbing, Toothy, Transformed, Transparent, Tubular, Tumultuous, Turbid, Turbulent, Ugly, Ultimate, Umber, Unclean, Uncouth, Undigested, Ungainly, Unhallowed, Unholy, Unknown, Unmasked, Unnatural, Unripe, Unseen, Unspeakable, Unutterable, Vague, Vaporous, Vast, Venous, Vermillion, Verminous, Vestigial, Vibrating, Vile, Viperous, Viscous, Vivid, Voluminous, Vomiting, Voracious, Vulpine, Wailing, Wan, Warped, Waxen, Webbed, Wet, Whirling, Whithered, Worm-Eaten, Wormy, Wretched, Writhing, Xanthous, Xenophobic, Yammering, Yonic, Zodiacal, Zymotic']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('data/products.txt', 'r') as f:\n",
    "    prod_words = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Magic Potions for Clarity, Beauty, and Energy\\n',\n",
       " 'Heirloom Organics Professional Medicine Pack\\n',\n",
       " 'Why am I so effing tired\\n',\n",
       " 'Brain Force Plus\\n',\n",
       " 'Chaga\\n',\n",
       " 'Caveman True Paleo Formula\\n',\n",
       " 'Colloidal Silver\\n',\n",
       " 'Silver Bullet\\n',\n",
       " 'Sun Potion\\n',\n",
       " 'Wake Up America Immune Support Blend 100% Organic Coffee\\n',\n",
       " 'Power Dust\\n',\n",
       " 'Relax & De-Stress Herbal Extract\\n',\n",
       " 'Vapour Beautyâ€™s Mesmerize Eye Shimmer\\n',\n",
       " 'Occu Power\\n',\n",
       " 'Sex Dust\\n',\n",
       " 'Super Male Vitality\\n',\n",
       " 'Survival Shield X-2\\n',\n",
       " 'Spirit Dust\\n',\n",
       " 'Balls in the Air\\n',\n",
       " 'Bio-True Selenium\\n',\n",
       " 'Brain Dust\\n',\n",
       " 'Z-Shield\\n',\n",
       " 'Deam Dust\\n',\n",
       " 'Child Ease\\n',\n",
       " '  ']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-b8a4fffd08ef>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprod_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprod_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprod_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"[a-zA-Z]+\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprod_words\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprod_words\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "\n",
    "prod_words = prod_words.split()\n",
    "prod_words = [\" \".join(re.findall(\"[a-zA-Z]+\", x)) for x in prod_words]\n",
    "prod_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = lc.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_pairs(corpus):\n",
    "    for i in range(len(corpus)-1):\n",
    "        yield (corpus[i], corpus[i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs = make_pairs(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object make_pairs at 0x00000245BBC5E620>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'On'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-ed510c19722f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mchain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'On'"
     ]
    }
   ],
   "source": [
    "word_dict = {}\n",
    "\n",
    "for word_1, word_2 in pairs:\n",
    "    if word_1 in word_dict.keys():\n",
    "        word_dict[word_1].append(word_2)\n",
    "    else:\n",
    "        word_dict[word_1] = [word_2]\n",
    " \n",
    "first_word = np.random.choice(corpus)\n",
    "\n",
    "while first_word.islower():\n",
    "    first_word = np.random.choice(corpus)\n",
    "\n",
    "chain = [first_word]\n",
    "\n",
    "n_words = 50\n",
    "\n",
    "for i in range(n_words):\n",
    "    chain.append(np.random.choice(word_dict[chain[-1]]))\n",
    "\n",
    "' '.join(chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['On']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
